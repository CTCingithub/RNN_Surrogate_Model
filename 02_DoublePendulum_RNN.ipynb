{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Surrogate Model for Double Pendulum\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Data and Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DoF': 2,\n",
       " 'PARAMETER': {'m1': 1.2, 'm2': 1.4, 'l1': 1.7, 'l2': 2.1, 'g': 9.8},\n",
       " 'DATASET': {'NUM_SAMPLES': 80,\n",
       "  'TIME_STEPS': 2000,\n",
       "  'SAMPLING_TIME': 0.001,\n",
       "  'SOLVER_SLICE': 100,\n",
       "  'RELTOL': 1.01e-08,\n",
       "  'ABSTOL': 1.01e-08},\n",
       " 'DATA_LOADER': {'BATCH_SIZE': 16, 'SEQ_LEN': 50, 'RATIO': [0.8, 0.1, 0.1]},\n",
       " 'NETWORK': {'NUM_LAYERS': 1, 'HIDDEN_SIZE': 16}}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "with open(\"Configuration/DoublePendulum.yaml\", \"r\") as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_seq = config[\"DATA_LOADER\"][\"SEQ_LEN\"]\n",
    "num_DoF = config[\"DoF\"]\n",
    "num_sample = config[\"DATASET\"][\"NUM_SAMPLES\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160080, 7)\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "\n",
    "MatData = loadmat(\"Data/DoublePendulum.mat\")\n",
    "TimeHistoryData = MatData[\"Data\"]\n",
    "print(TimeHistoryData.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156080, 50, 6)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "\n",
    "\n",
    "def PreprocessData(DATA, SEQ_LEN, TIMESTAMP=False):\n",
    "    # DATA's shape is num_sample x num_features x num_time_steps\n",
    "    sequences = []\n",
    "    for i in range(DATA.shape[0] - SEQ_LEN + 1):\n",
    "        if TIMESTAMP:\n",
    "            if not np.isnan(DATA[i : i + SEQ_LEN, :]).any():\n",
    "                sequences.append(DATA[i : i + SEQ_LEN, :])\n",
    "        elif not np.isnan(DATA[i : i + SEQ_LEN, :]).any():\n",
    "            sequences.append(DATA[i : i + SEQ_LEN, 1:])\n",
    "    return np.array(sequences)\n",
    "\n",
    "\n",
    "DataSet = PreprocessData(TimeHistoryData, len_seq, TIMESTAMP=False)\n",
    "DataSet.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Data Set of Sequencial Data for Training, Validation and Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateDataLoader(DATA, BATCH_SIZE=16, RATIO=None, SHUFFLE=True):\n",
    "    if RATIO is None:\n",
    "        RATIO = [0.8, 0.1, 0.1]\n",
    "    DataSet = TensorDataset(DATA)\n",
    "    TrainSize = int(len(DataSet) * RATIO[0])\n",
    "    ValSize = int(len(DataSet) * RATIO[1])\n",
    "    TestSize = len(DataSet) - TrainSize - ValSize\n",
    "\n",
    "    train_dataset, val_dataset, test_dataset = random_split(\n",
    "        DataSet, [TrainSize, ValSize, TestSize]\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=SHUFFLE)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=SHUFFLE)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=SHUFFLE)\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "\n",
    "DataSet = torch.tensor(DataSet, dtype=torch.float32)\n",
    "TrainLoader, ValLoader, TestLoader = CreateDataLoader(\n",
    "    DataSet,\n",
    "    BATCH_SIZE=config[\"DATA_LOADER\"][\"BATCH_SIZE\"],\n",
    "    RATIO=config[\"DATA_LOADER\"][\"RATIO\"],\n",
    "    SHUFFLE=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define RNN Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN Cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_Cell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, bias=True):\n",
    "        super(RNN_Cell, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.Tensor(hidden_size))\n",
    "        else:\n",
    "            self.register_parameter(\"bias\", None)\n",
    "\n",
    "        self.W_hh = nn.Linear(hidden_size, hidden_size)\n",
    "        self.W_xh = nn.Linear(input_size, hidden_size)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        h_t = self.W_hh(h) + self.W_xh(x)\n",
    "        if self.bias is not None:\n",
    "            h_t += self.bias\n",
    "        return torch.tanh(h_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialModel(nn.Module):\n",
    "    def __init__(self, core, input_size, hidden_size, output_size, num_layers=1):\n",
    "        super(SequentialModel, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NCP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
